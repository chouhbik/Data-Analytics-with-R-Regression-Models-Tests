---
title: "6 - Logarithmic Transformations"
author: "Kamal Chouhbi"
output:
  html_notebook:
    theme: simplex
    toc: yes
    toc_depth: 4
---


### **Introduction**

When the relationship between a predictor and the response appears to be non-linear, we can consider transforming one or both of the variables in hopes that the new variables will exhibit a linear relationship. In this lesson, we will consider two synthetic examples where $Y$ seems to depend exponentially on $X$. We will consider the following models for these examples.

* Linear Model: $Y = \beta_0 + \beta_1 X + \varepsilon$.

* Exponential Model: $Y = \beta_0 + \beta_1 e^X + \varepsilon$.

* Log-Level Model: $\ln(Y) = \beta_0 + \beta_1 X + \varepsilon$

* Log-Log Model: $\ln(Y) = \beta_0 + \beta_1 \ln(X) + \varepsilon$

### **Example 1**

#### **Load and Explore the Data**

We will load the example data from a tab separated file located at the path `data/log_ex01.txt`. 

```{r}
ex01 <- read.table("data/log_ex01.txt", sep="\t", header=TRUE)
summary(ex01)
```

We can see from a plot of the data that $X$ and $Y$ seem to exhibit a non-linear relationship. We also see that the variance in $Y$ seems to increase with $X$. 

```{r}
plot(y ~ x, ex01, pch=21, col="black", bg="cyan")
```

#### **Model 1: Linear Model**

We will begin by creating a fitted linear model of the form: $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X$ 

```{r}
ex01_m1 <- lm(y ~ x, ex01)
summary(ex01_m1) 
```

We plot the fitted line on top of the scatter plot. 

```{r}
plot(y ~ x, ex01, pch=21, col="black", bg="cyan")
abline(ex01_m1$coefficients, col="darkred", lwd=2)
```


We can see strong evidence of a non-linear trend, as well as heteroskedasticity in the residual plot below. 

```{r}
res1 <- ex01_m1$residuals

plot(res1 ~ ex01$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")
abline(h=0, col="darkred", lwd=2)
```

We can assess normality of the residuals using a Shapiro-Wilk test, a histogram, and a QQ-plot. 

```{r}
shapiro.test(res1)
```

The Shapiro-Wilk test strongly suggests non-normality of the residuals. The histogram and QQ-plot reveal that the residuals are right-skewed. 

```{r}
par(mfrow=c(1,2))
hist(res1, col='orchid')
qqnorm(res1)
qqline(res1)
par(mfrow=c(1,1))
```

#### **Model 2: Exponetial Model**

We will now create a fitted model of the form $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 e^X$.

```{r}
ex01_m2 <- lm(y ~ exp(x), ex01)
summary(ex01_m2) 
```

We plot the fitted line on top of the scatter plot. We see that the fitted line does seem to capture the relationship between `X` and `Y` reasonably well. 


```{r}
ptn = seq(from=2,to=8, by=0.1)

plot(y ~ x, ex01, pch=21, col="black", bg="cyan")
lines(ptn, predict(ex01_m2, data.frame(x=ptn)), col="darkred", lwd=2)
```

The residual plot below shows some evidence of a very slight trend, as well as severe heteroskedasticity. 


```{r}
res2 <- ex01_m2$residuals
plot(res2 ~ ex01$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")
abline(h=0, col="darkred", lwd=2)
```

The figure below shows a scatter plot of the data, along with the fitted curve and a 95% prediction band. We can see that the band is too wide in some places, and too narrow in others. This is a direct response of the heteroskedasticity in the residuals. 

```{r}
plot(y ~ x, ex01, pch=21, col="black", bg="cyan")
p2 <- predict(ex01_m2, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, p2[,"fit"], col="darkred", lwd=2)
lines(ptn, p2[,"lwr"], col="darkorange", lwd=2)
lines(ptn, p2[,"upr"], col="darkorange", lwd=2)
```

We can assess normality of the residuals using a Shapiro-Wilks test, a histogram, and a QQ-plot. 

```{r}
shapiro.test(res2)
```


```{r}
par(mfrow=c(1,2))
hist(res2, col='orchid')
qqnorm(res2)
qqline(res2)
par(mfrow=c(1,1))
```


#### **Model 3: Log-Level Model**

We now consider a fitted model of the form: $\ln(\hat Y) = \hat{\beta}_0 + \hat{\beta}_1 X$. 

We will start by plotting our new response, $\ln(Y)$ against $X$. This plot exhibits a strong linear relationship. 

```{r}
plot(log(y) ~ x, ex01, pch=21, col="black", bg="cyan")
```

We will now create our model. 

```{r}
ex01_m3 <- lm(log(y) ~ x, ex01)
summary(ex01_m3) 
```

The residual plot below displays no apparent trend or heteroskedasticity. Note that these are residuals of $\ln(Y)$, and not $Y$. 

```{r}
res3 <- ex01_m3$residuals
plot(res3 ~ ex01$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")

abline(h=0, col="darkred", lwd=2)
```

We now assess the normality of the residuals with a Shapiro-Wilks test, a histogram, and a QQ-plot.

```{r}
shapiro.test(res3)
```


```{r}
par(mfrow=c(1,2))
hist(res3, col='orchid')
qqnorm(res3)
qqline(res3)
par(mfrow=c(1,1))
```

These plots suggest that the residuals were likey drawn from a normal (or perhaps very slightly left-skewed) distribution. 
 
We will add the fitted curve and  to the scatter plot of $\ln(Y)$ against $X$. 


```{r}
plot(log(y) ~ x, ex01, pch=21, col="black", bg="cyan")

p3 <- predict(ex01_m3, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, p3[,"fit"], col="darkred", lwd=2)
lines(ptn, p3[,"lwr"], col="darkorange", lwd=2)
lines(ptn, p3[,"upr"], col="darkorange", lwd=2)
```

We can exponentiate the values of $\ln(Y)$ to transform the vertical axis back in terms of $Y$. Notice that the fitted curve does seem to provide a good fit for the data, and the transformed prediction band seems to account for the heteroskedasticity. 

```{r}
plot(y ~ x, ex01, pch=21, col="black", bg="cyan")

p3 <- predict(ex01_m3, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, exp(p3[,"fit"]), col="darkred", lwd=2)
lines(ptn, exp(p3[,"lwr"]), col="darkorange", lwd=2)
lines(ptn, exp(p3[,"upr"]), col="darkorange", lwd=2)
```

#### **Model 4: Log-Log Model**

We now consider a fitted model of the form: $\ln(\hat Y) = \hat{\beta}_0 + \hat{\beta}_1 \ln(X)$. 

We will start by plotting $\ln(Y)$ against $\ln(X)$. This plot exhibits a slight non-linearity. 

```{r}
plot(log(y) ~ log(x), ex01, pch=21, col="black", bg="cyan")
```

We will now create our model. 

```{r}
ex01_m4 <- lm(log(y) ~ log(x), ex01)
summary(ex01_m4)
```

The previously observed non-linearity is readily apparent in the residual plot. 

```{r}
res4 <- ex01_m4$residuals
plot(res4 ~ ex01$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")

abline(h=0, col="darkred", lwd=2)
```

We assess normality of the residuals using a Shapiro-Wilks test, a histogram, and a QQ-plot.



```{r}
shapiro.test(res4)
```


```{r}
par(mfrow=c(1,2))
hist(res4, col='orchid')
qqnorm(res4)
qqline(res4)
par(mfrow=c(1,1))
```

#### **Comparison of Models**

Of the models we have considered, Model 3 has the highest $r^2$ value. Note, however, that since the response ($Y$) in the first two models is different from the response in the second pair of models ($\ln(Y)$), these $r^2$ values are not directly comparable. 

```{r}
m1_r2 <- summary(ex01_m1)$r.squared
m2_r2 <- summary(ex01_m2)$r.squared
m3_r2 <- summary(ex01_m3)$r.squared
m4_r2 <- summary(ex01_m4)$r.squared

cbind(m1_r2, m2_r2, m3_r2, m4_r2)
```

If we are careful about performing the appropriate transformations in the log-level and log-log models, we can directly compare the SSE scores. However, keep in mind that these values only tell part of the story. As we see, Model 2 has the lowest SSE score, but as we noted, it has serious issues resulting from heteroskedasticity. 

```{r}
sse1 <- sum((ex01$y - ex01_m1$fitted.values)^2)
sse2 <- sum((ex01$y - ex01_m2$fitted.values)^2)
sse3 <- sum((ex01$y - exp(ex01_m3$fitted.values))^2)
sse4 <- sum((ex01$y - exp(ex01_m4$fitted.values))^2)

cbind(sse1, sse2, sse3, sse4)
```

We will use Model 3 going forward. It has a high $r^2$ value, and seems to satisfy the Gauss-Markov assumptions. 


#### **Generating Predictions with the Log-Level Model** 

When using a log-level model to create predictions for $Y$, we need to first generate a prediction for $\ln(Y)$, and then exponentiate. Let's construct a 95% prediction interval for $Y$ when $X = 6.5$.


```{r}
ln_yhat = predict(ex01_m3, data.frame(x=c(6.5)), interval="prediction", level=0.95)
yhat = exp(ln_yhat)
yhat
```

### **Example 2**

#### **Load and Explore the Data**

We will load the example data from a tab separated file located at the path `data/log_ex02.txt`.

```{r}
ex02 <- read.table("data/log_ex02.txt", sep="\t", header=TRUE)
summary(ex02)
```

We can see from a plot of the data that $X$ and $Y$ seem to exhibit a non-linear relationship. We also see that the variance in $Y$ seems to increase with $X$.

```{r}
plot(y ~ x, ex02, pch=21, col="black", bg="cyan")
```



#### **Model 1: Linear Model**

We will begin by creating a fitted linear model of the form: $\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 X$ 

```{r}
ex02_m1 <- lm(y ~ x, ex02)
summary(ex02_m1) 
```

We plot the fitted line on top of the scatter plot.


```{r}
plot(y ~ x, ex02, pch=21, col="black", bg="cyan")
abline(ex02_m1$coefficients, col="darkred", lwd=2)
```


We can see strong evidence of a non-linear trend, as well as heteroskedasticity in the residual plot below.


```{r}
res1 <- ex02_m1$residuals
plot(res1 ~ ex02$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")

abline(h=0, col="darkred", lwd=2)
```

We can assess normality of the residuals using a Shapiro-Wilk test, a histogram, and a QQ-plot.

```{r}
shapiro.test(res1)
```

The Shapiro-Wilk test strongly suggests non-normality of the residuals. The histogram and QQ-plot reveal that the residuals are right-skewed.

```{r}

par(mfrow=c(1,2))
hist(res1, col='orchid')
qqnorm(res1)
qqline(res1)
par(mfrow=c(1,1))
```


#### **Model 2: Log-Level Model**

Noting the apparent heteroskedasticity in the model, we will now consider a fitted model of the form: $\ln(\hat{Y}) = \hat{\beta}_0 + \hat{\beta}_1 X$.  

We will start by plotting the response $\ln(Y)$ against $X$. This plot exhibits a somewhat non-linear relationship.


```{r}
plot(log(y) ~ x, ex02, pch=21, col="black", bg="cyan")
```

A summary of the log-level model is shown below. 

```{r}
ex02_m2 <- lm(log(y) ~ x, ex02)
summary(ex02_m2) 
```

Let's consider the residual plot. Note that these are residuals of $\ln(Y)$, and not $Y$. 

The previously observed non-linearity is apparent in the residual plot.

```{r}
res2 <- ex02_m2$residuals

plot(res2 ~ ex02$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")

abline(h=0, col="darkred", lwd=2)
```

We now assess the normality of the residuals with a histogram and a QQ-plot.

```{r}
shapiro.test(res2)
```

The figure below shows a scatter plot of $\ln(Y)$ against $X$. It also displays the fitted curve, as well as a 95% prediction band. 


```{r}
plot(log(y) ~ x, ex02, pch=21, col="black", bg="cyan")

p2 <- predict(ex02_m2, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, p2[,"fit"], col="darkred", lwd=2)
lines(ptn, p2[,"lwr"], col="darkorange", lwd=2)
lines(ptn, p2[,"upr"], col="darkorange", lwd=2)
```

We can exponentiate the values of $\ln(Y)$ to transform the vertical axis back in terms of $Y$. 

```{r}
plot(y ~ x, ex02, pch=21, col="black", bg="cyan")

p2 <- predict(ex02_m2, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, exp(p2[,"fit"]), col="darkred", lwd=2)
lines(ptn, exp(p2[,"lwr"]), col="darkorange", lwd=2)
lines(ptn, exp(p2[,"upr"]), col="darkorange", lwd=2)
```


#### **Model 3: Log-Log Model**

We now consider a fitted model of the form: $\ln(\hat Y) = \hat{\beta}_0 + \hat{\beta}_1 \ln(X)$. 

We start by plotting $\ln(Y)$ against $\ln(X)$. This plot exhibits a strong linear relationship. 

```{r}
plot(log(y) ~ log(x), ex02, pch=21, col="black", bg="cyan")
```

A summary of the fitted model is shown below. 


```{r}
ex02_m3 <- lm(log(y) ~ log(x), ex02)
summary(ex02_m3) 
```

The residual plot below displays no apparent trend or heteroskedasticity.


```{r}
res3 <- ex02_m3$residuals

plot(res3 ~ ex02$x, pch=21, col="black", bg="cyan", 
     xlab="x", ylab="Residuals", main="Residual Plot")

abline(h=0, col="darkred", lwd=2)
```

There is no apparent heteroskedasticity or trend in this residual plot.  


We now assess the normality of the residuals.

```{r}
shapiro.test(res3)
```


```{r}
par(mfrow=c(1,2))
hist(res3, col='orchid')
qqnorm(res3)
qqline(res3)
par(mfrow=c(1,1))
```


We will add the fitted curve and  to the scatter plot of $\ln(Y)$ against $X$. 



```{r}
plot(log(y) ~ log(x), ex02, pch=21, col="black", bg="cyan")

p3 <- predict(ex02_m3, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(log(ptn), p3[,"fit"], col="darkred", lwd=2)
lines(log(ptn), p3[,"lwr"], col="darkorange", lwd=2)
lines(log(ptn), p3[,"upr"], col="darkorange", lwd=2)
```

We can exponentiate the values of $ln(Y)$ to transform back to be in terms of $Y$. 

```{r}
plot(y ~ x, ex02, pch=21, col="black", bg="cyan")

p3 <- predict(ex02_m3, newdata=data.frame(x=ptn), interval="prediction", level=0.95)
lines(ptn, exp(p3[,"fit"]), col="darkred", lwd=2)
lines(ptn, exp(p3[,"lwr"]), col="darkorange", lwd=2)
lines(ptn, exp(p3[,"upr"]), col="darkorange", lwd=2)
```


#### **Generating Predictions with the Log-Log Model** 

When using a log-log model to create predictions for $Y$, we need to first generate a prediction for $\ln(Y)$, and then exponentiate. Let's construct a 95% prediction interval for $Y$ when $X = 6.5$.


```{r}
ln_yhat = predict(ex02_m3, data.frame(x=c(6.5)), interval="prediction", level=0.95)
yhat = exp(ln_yhat)
yhat
```
































